{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request as urlrequest\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"uscities.csv\")\n",
    "information = ['city','state_id','lat','lng']\n",
    "loc_df = df.head(10)[information]\n",
    "airport = ['JFK','LAX','ORD','MIA','DFW','PHL','HOU','ATL','WAS','BOS']\n",
    "loc_df['airport'] = airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "base  = \"http://forecast.weather.gov/MapClick.php?\"\n",
    "lat  = loc_df['lat'].to_numpy()\n",
    "lng  = loc_df['lng'].to_numpy()\n",
    "url = []\n",
    "for lati,lngi in zip(lat,lng):\n",
    "    url.append(f'{base}lat={lati}&lon={lngi}')\n",
    "\n",
    "temp_day1 =[]\n",
    "temp_day2 =[]\n",
    "temp_day3 =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    page = urlrequest.urlopen(url[i]).read()\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    weather = soup.find(id = 'seven-day-forecast-container')\n",
    "    date = weather.find_all(class_='period-name')\n",
    "    status = weather.find_all(class_='short-desc')\n",
    "    temp = weather.find_all(class_='temp')\n",
    "    day_count = 0\n",
    "    for j in range(9):\n",
    "        date_i=date[j].get_text()\n",
    "        temp_i = temp[j].get_text()\n",
    "        temp_digit = 0\n",
    "        for word in temp_i.split():\n",
    "            if word.isdigit():\n",
    "                temp_digit = int(word)\n",
    "\n",
    "        if(date_i != \"Tonight\" and date_i.find('Night') == -1):\n",
    "            if(day_count == 0 ):\n",
    "                temp_day1.append(temp_digit)\n",
    "                day_count = day_count+1\n",
    "            elif(day_count == 1):\n",
    "                temp_day2.append(temp_digit)\n",
    "                day_count = day_count+1\n",
    "            elif(day_count == 2):\n",
    "                temp_day3.append(temp_digit)\n",
    "                day_count= day_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df['day1'] = temp_day1\n",
    "loc_df['day2'] = temp_day2\n",
    "loc_df['day3'] = temp_day3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "\n",
    "tomorrow = today + timedelta(days=1)\n",
    "tomorrow_str = str(tomorrow.year) + \"-\"+ str(tomorrow.month) + \"-\"+ str(tomorrow.day)\n",
    "day_after_today = today + timedelta(days=2)\n",
    "day_after_today_str = str(day_after_today.year) + \"-\"+ str(day_after_today.month) + \"-\"+ str(day_after_today.day)\n",
    "day_after_tomorrow = today + timedelta(days=3)\n",
    "day_after_tomorrow_str = str(day_after_tomorrow.year) + \"-\"+ str(day_after_tomorrow.month) + \"-\"+ str(day_after_tomorrow.day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-38dc91eb6c43>:29: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"/Users/haoyuhuang/Downloads/chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "depart = 'DTW'\n",
    "#destinations = loc_df['airport'].tolist()[0:6] + loc_df['airport'].tolist()[8:10]\n",
    "destinations = ['ORD' ]\n",
    "dates = [tomorrow_str,day_after_today_str,day_after_tomorrow_str]\n",
    "\n",
    "final_df = pd.DataFrame({'depart': [],\n",
    "                         'arrive': [],\n",
    "                         'date': [],\n",
    "                         'depart_time': [],\n",
    "                         'arrival_time': [],\n",
    "                         'price': [],\n",
    "                         'airline': [],\n",
    "                         'duration': []})\n",
    "\n",
    "for destination in destinations:\n",
    "\n",
    "    time.sleep(20)\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        url = f'https://www.kayak.com/flights/{depart}-{destination}/{date}?sort=bestflight_a'\n",
    "\n",
    "        driver = webdriver.Chrome(\"/Users/haoyuhuang/Downloads/chromedriver\")\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "        # departure times\n",
    "        departure_time = []\n",
    "        departure_times = soup.findAll('span', attrs={'class': 'depart-time base-time'})\n",
    "        for times in departure_times:\n",
    "            departure_time.append(times.text)\n",
    "\n",
    "        # arrival times\n",
    "        arrival_time = []\n",
    "        arrival_times = soup.findAll('span', attrs={'class': 'arrival-time base-time'})\n",
    "        for times in arrival_times:\n",
    "            arrival_time.append(times.text)\n",
    "\n",
    "        # prices\n",
    "        price = []\n",
    "        price_tag = re.compile('Common-Booking-MultiBookProvider(.*) Theme-featured-large(.*) multi-row(.*)')\n",
    "        prices = soup.findAll('div', attrs={'class': price_tag})\n",
    "        for price_i in prices:\n",
    "            price.append(price_i.text.split('\\n')[4].strip())\n",
    "\n",
    "        # airlines\n",
    "        airline = []\n",
    "        airlines = soup.findAll('div', attrs={'class': 'bottom', 'dir': 'ltr'})\n",
    "        for airline_i in airlines:\n",
    "            airline.append(airline_i.text.replace('\\n', ''))\n",
    "\n",
    "        # durations\n",
    "        duration = []\n",
    "        durations = soup.findAll('div', attrs={'class': 'section duration allow-multi-modal-icons'})\n",
    "        for duration_i in durations:\n",
    "            duration.append(' '.join(duration_i.text.split(' ')[:2]).replace('\\n', ''))\n",
    "\n",
    "        df = pd.DataFrame({'depart': depart,\n",
    "                           'arrive': destination,\n",
    "                           'date': date,\n",
    "                           'depart_time': departure_time[:5],\n",
    "                           'arrival_time': arrival_time[:5],\n",
    "                           'price': price[:5],\n",
    "                           'airline': airline[:5],\n",
    "                           'duration': duration[:5]})\n",
    "\n",
    "        final_df = pd.concat([final_df, df], ignore_index=True, sort=False)\n",
    "        driver.close()\n",
    "        time.sleep(20)\n",
    "\n",
    "final_df.to_csv('flight.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.merge(loc_df, final_df, left_on=\"airport\", right_on=\"arrive_at\")\n",
    "newdf = newdf.drop(['state_id','lat','lng'],axis=1)\n",
    "newdf.to_csv(\"final_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f901d768b51ab5af11dc080dcb7a8a5ded98c3b1e6a8a32a4c02bf1176767a94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
